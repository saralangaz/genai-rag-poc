services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile.fastapi
    platform: linux/amd64
    image: poc-genai  # Replace with your Docker image name/tag for poc-app
    ports:
      - "8000:8000"
    environment:
      - PYTHONUNBUFFERED=1  # Ensures Python output is sent straight to terminal
    depends_on:
      - ollama  # Ensure poc-app starts after ollama
    networks:
      - app-network  # Attach to the backend network for inter-container communication
  
  gradio:
    build:
      context: .
      dockerfile: Dockerfile.gradio
    ports:
      - "7860:7860"
    depends_on:
      - backend
    networks:
      - app-network

  ollama:
    platform: linux/amd64
    image: ollama/ollama:0.2.1 # Replace with your Docker image name/tag for ollama
    volumes:
      - ollama_data:/root/.ollama
      - ./entrypoint.sh:/entrypoint.sh
    ports:
      - "11434:11434"
    networks:
      - app-network  # Attach to the backend network for inter-container communication
    entrypoint: ["/usr/bin/bash", "/entrypoint.sh"]
  
  weaviate:
    platform: linux/amd64
    command:
    - --host
    - 0.0.0.0
    - --port
    - '8080'
    - --scheme
    - http
    image: cr.weaviate.io/semitechnologies/weaviate:1.25.9
    ports:
    - 8080:8080
    - 50051:50051
    volumes:
    - weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      ENABLE_MODULES: 'text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai'
      CLUSTER_HOSTNAME: 'node1'
    networks:
      - app-network

networks:
  app-network:
    driver: bridge

volumes:
  ollama_data:
  weaviate_data:
  index_data:
    driver: local
  backups:
    driver: local
